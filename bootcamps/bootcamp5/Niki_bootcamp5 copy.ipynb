{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All you need is ♥️… And a pet!\n",
    "\n",
    "Some of you didn't get any flower on Valentine's day but you worry not, Jerry has a solution for you. Get ready to adopt a pet!\n",
    "\n",
    "<img src=\"img/dataset-cover.jpg\" width=\"920\">\n",
    "\n",
    "Here we are going to build a classifier to predict whether an animal from an animal shelter will be adopted or not (aac_intakes_outcomes.csv, available at: https://www.kaggle.com/aaronschlegel/austin-animal-center-shelter-intakes-and-outcomes/version/1#aac_intakes_outcomes.csv). You will be working with the following features:\n",
    "\n",
    "1. *animal_type:* Type of animal. May be one of 'cat', 'dog', 'bird', etc.\n",
    "2. *intake_year:* Year of intake\n",
    "3. *intake_condition:* The intake condition of the animal. Can be one of 'normal', 'injured', 'sick', etc.\n",
    "4. *intake_number:* The intake number denoting the number of occurrences the animal has been brought into the shelter. Values higher than 1 indicate the animal has been taken into the shelter on more than one occasion.\n",
    "5. *intake_type:* The type of intake, for example, 'stray', 'owner surrender', etc.\n",
    "6. *sex_upon_intake:* The gender of the animal and if it has been spayed or neutered at the time of intake\n",
    "7. *age_upon\\_intake_(years):* The age of the animal upon intake represented in years\n",
    "8. *time_in_shelter_days:* Numeric value denoting the number of days the animal remained at the shelter from intake to outcome.\n",
    "9. *sex_upon_outcome:* The gender of the animal and if it has been spayed or neutered at time of outcome\n",
    "10. *age_upon\\_outcome_(years):* The age of the animal upon outcome represented in years\n",
    "11. *outcome_type:* The outcome type. Can be one of ‘adopted’, ‘transferred’, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from itertools import combinations \n",
    "import ast\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "\n",
    "data_folder = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Load the dataset and convert categorical features to a suitable numerical representation (use dummy-variable encoding). \n",
    "- Split the data into a training set (80%) and a test set (20%). Pair each feature vector with the corresponding label, i.e., whether the outcome_type is adoption or not. \n",
    "- Standardize the values of each feature in the data to have mean 0 and variance 1.\n",
    "\n",
    "The use of external libraries is not permitted in part A, except for numpy and pandas. \n",
    "If you notice missing values in the imported entries, you have to deal with them. Make informed choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['animal_type', 'intake_year', 'intake_condition', 'intake_number', 'intake_type', 'sex_upon_intake', \\\n",
    "          'age_upon_intake_(years)', 'time_in_shelter_days', 'sex_upon_outcome', 'age_upon_outcome_(years)', \\\n",
    "          'outcome_type']\n",
    "original_data = pd.read_csv(data_folder+'aac_intakes_outcomes.csv', usecols=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('The length of the data with all rows is : {}'.format(len(original_data)))\n",
    "original_data.dropna(inplace=True)\n",
    "print('The length of the data without the rows with nan value is: {}'.format(len(original_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below can used to split the data to training/testing. The `data_to_split` should be the clean dataframe from A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_split = ...\n",
    "\n",
    "def split_set(data_to_split, ratio=0.8):\n",
    "    mask = np.random.rand(len(data_to_split)) < ratio\n",
    "    return [data_to_split[mask].reset_index(drop=True), data_to_split[~mask].reset_index(drop=True)]\n",
    "\n",
    "[train, test] = split_set(data_to_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Train a logistic regression classifier on your training set. Logistic regression returns probabilities as predictions, so in order to arrive at a binary prediction, you need to put a threshold on the predicted probabilities. \n",
    "- For the decision threshold of 0.5, present the performance of your classifier on the test set by displaying the confusion matrix. Based on the confusion matrix, manually calculate accuracy, precision, recall, and F1-score with respect to the positive and the negative class. \n",
    "\n",
    "- The features in the testing set must be matched with the traning set.\n",
    "\n",
    "- You can use the functions below to compute and plot a confusion matrix as well as compute all relevant scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(true_label, prediction_proba, decision_threshold=0.5): \n",
    "    \n",
    "    predict_label = (prediction_proba[:,1]>decision_threshold).astype(int)   \n",
    "                                                                                                                       \n",
    "    TP = np.sum(np.logical_and(predict_label==1, true_label==1))\n",
    "    TN = np.sum(np.logical_and(predict_label==0, true_label==0))\n",
    "    FP = np.sum(np.logical_and(predict_label==1, true_label==0))\n",
    "    FN = np.sum(np.logical_and(predict_label==0, true_label==1))\n",
    "    \n",
    "    confusion_matrix = np.asarray([[TP, FP],\n",
    "                                    [FN, TN]])\n",
    "    return confusion_matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix):\n",
    "    [[TP, FP],[FN, TN]] = confusion_matrix\n",
    "    label = np.asarray([['TP {}'.format(TP), 'FP {}'.format(FP)],\n",
    "                        ['FN {}'.format(FN), 'TN {}'.format(TN)]])\n",
    "    \n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=['Yes', 'No'], columns=['Positive', 'Negative']) \n",
    "    \n",
    "    return sn.heatmap(df_cm, cmap='YlOrRd', annot=label, annot_kws={\"size\": 16}, cbar=False, fmt='')\n",
    "\n",
    "\n",
    "def compute_all_score(confusion_matrix, t=0.5):\n",
    "    [[TP, FP],[FN, TN]] = confusion_matrix.astype(float)\n",
    "    \n",
    "    accuracy =  (TP+TN)/np.sum(confusion_matrix)\n",
    "    \n",
    "    precision_positive = TP/(TP+FP) if (TP+FP) !=0 else np.nan\n",
    "    precision_negative = TN/(TN+FN) if (TN+FN) !=0 else np.nan\n",
    "    \n",
    "    recall_positive = TP/(TP+FN) if (TP+FN) !=0 else np.nan\n",
    "    recall_negative = TN/(TN+FP) if (TN+FP) !=0 else np.nan\n",
    "\n",
    "    F1_score_positive = 2 *(precision_positive*recall_positive)/(precision_positive+recall_positive) if (precision_positive+recall_positive) !=0 else np.nan\n",
    "    F1_score_negative = 2 *(precision_negative*recall_negative)/(precision_negative+recall_negative) if (precision_negative+recall_negative) !=0 else np.nan\n",
    "\n",
    "    return [t, accuracy, precision_positive, recall_positive, F1_score_positive, precision_negative, recall_negative, F1_score_negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit a cute logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show confusion matrix and scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Vary the value of the threshold in the range from 0 to 1 and visualize the value of accuracy, precision, recall  and F1-score (with respect to both classes) as a function of the threshold.\n",
    "\n",
    "Here we expect one plot for the accuracy and then 2 sets of 3 plots for each of the classes, i.e. precision, recall and F1 score for the positive class and precision, recall and F1 score for the negative class.\n",
    "\n",
    "### Comment on the results. What do you observe?\n",
    "\n",
    "In clinic 3, we will focus on the AUROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#show cute plots here (in total 7 plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// comments here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) Plot in a bar chart the coefficients of the logistic regression sorted by their contribution to the prediction.\n",
    "\n",
    "### Interpret the results of the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the bartplot here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// comments here //"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
