{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "895feafc",
   "metadata": {},
   "source": [
    "(Placeholder for your group #)\n",
    "\n",
    "(Placeholder for your names)\n",
    "\n",
    "(Placeholder for your i-numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c85891",
   "metadata": {},
   "source": [
    "**Use of genAI tools (e.g. chatGPT), websites (e.g. stackoverflow)**: *list websites where you found code (or other info) as well as include information on how you used genAI tools*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08998c",
   "metadata": {},
   "source": [
    "# Data Analysis, Clinic 2\n",
    "\n",
    "By completing and delivering the clinic tasks you will know how to :\n",
    "\n",
    "- Preprocess data and make it amenable to statistical analysis and machine learning models;\n",
    "- Train and test out-of-the-box machine learning models in `sklearn`;\n",
    "- Carry out simple logistic regression analysis;\n",
    "- Evaluate classification models based on different metrics;\n",
    "- Assess how your model performance can improve\n",
    "- Reflect on the greater impact of the models you develop\n",
    "\n",
    "---\n",
    "\n",
    "## Important Dates\n",
    "\n",
    "- Homework release: Fri, 7th Feb\n",
    "- **Homework due**: Mon, 17th Feb late night (wildcards possible, apply to the group)\n",
    "\n",
    "---\n",
    "\n",
    "##  Some rules\n",
    "\n",
    "* We have provided `TODO` comments in the code cells that you need to fill out with your solutions. For some questions, we have also provided `Your response` comments, where you should provide a textual answer.\n",
    "\n",
    "* You are allowed to use any built-in Python library that is included in the `requirements.txt` for this homework. If you use any additional library, this may complicate the grading process, and we reserve the right to penalize your grade for unnecessary complexity of the solution. All the questions can be solved with the libraries in `requirements.txt`.\n",
    "\n",
    "* Make sure that you include a proper amount/mix of comments, results and code. More specifically, be sure to provide a concise textual description of your thought process, the assumptions you made, the solution you implemented, and explanations for your answers. A notebook that only has code cells will not suffice. To avoid confusion: use short comments for longer code answers.\n",
    "\n",
    "* Back up any hypotheses and claims with data, since this is an important aspect of the course.\n",
    "\n",
    "* Please write all your comments in English, and use meaningful variable names (as possible) in your code. \n",
    "\n",
    "* In the end, make sure that all cells are executed properly and everything you need to show is in your (execucted) notebook. We will not run your notebook for you! \n",
    "\n",
    "- In continuation to the previous point, interactive plots, such as those generated using the ‘plotly’ package, should be strictly avoided! Make sure to print results and/or dataframes that confirm you have properly addressed the task.\n",
    "\n",
    "* You are asked to deliver **only your executed notebook file, .ipnyb** and nothing else. If you deliver other files, we will not grade anything.\n",
    "\n",
    "* Honor code applies to these tasks. If you are not certain about an action, consult with Jerry.\n",
    "\n",
    "**A Note from Jerry on using Language Models (LMs)**\n",
    "\n",
    "If you try hard enough, you will likely get away with cheating (that does not only apply to LMs). Fortunately, my job is not to police, but rather to educate you. So, please consider the following:\n",
    "\n",
    "I assume that you are taking this course to learn something! LMs are not always right ([they often fail in silly ways](https://community.openai.com/t/why-9-11-is-larger-than-9-9-incredible/869824/4)). This course should prepare you to detect when they are wrong!\n",
    "\n",
    "I don't restrict the use of LMs because I see the value of being helped when coding (esp. in the context of pandas dataframes nightmare :)). Based on what we saw last year in your notebooks, it's pretty clear when you \"copy\" some code and then you struggle to interpret the results. This is the essence of this course and of the skills you should try build for yourself: Many people can run fancy models these days but not many people can interpret the results correctly. Try to be the latter ones.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Grading \n",
    "- The homework has a total of 100 points, distributed as follows:\n",
    "    - Part 1: Data Preprocessing (20 points)\n",
    "    - Part 2: Linear Regression (30 points)\n",
    "    - Part 3: Supervised Learning (40 points)\n",
    "    - Part 4: The Aftermath (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6f0a9b",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "Within DACS, you are excited to start an internship as a data scientist.\n",
    "After rounds of interviews, you have been selected to work with the biggest car dealership in the Netherlands !\n",
    "\n",
    "Your mentor at the company Jerasimosu, has explained to you that the company is interested in a pricing model for used cars. \n",
    "\n",
    "- Jerasimosu: \"We have a lot of used cars in our inventory, and we need to determine the price at which we should sell these cars. We have some ideas about the factors that influence the price of a used car, but so far we have just been using our experience and intuition to determine the price of a used car. Sometimes it works, but probably we can do better and a more data-driven approach would also help our new employees in the sales team as they have less experience.\"\n",
    "\n",
    "- You: \"That sounds like a great project! What kind of data do we have?\"\n",
    "\n",
    "- Jerasimosu: \"We sell all kinds of cars here, but maybe we can start with a specific brand and model. For example, the Toyota Corolla is the best-selling car worldwide in 2023, and we have a lot of data on it. We can start by analyzing the data on used Toyota Corolla cars. If it works well, we can extend the analysis to other brands.\"\n",
    "\n",
    "The dataset contains the following columns:\n",
    "\n",
    "- `Age`: Age of the car in months.\n",
    "- `Mileage`: Number of distance the car has been driven. (km or miles)\n",
    "- `FuelType`: Fuel type of the car (Petrol, Diesel, or CNG)\n",
    "- `HP`: Horsepower\n",
    "- `MetColor`: Is the color of the car metallic? (Yes=1, No=0)\n",
    "- `Automatic`: Is the car automatic? (Yes=1, No=0)\n",
    "- `CC`: Cylinder volume in cubic centimeters\n",
    "- `Doors`: Number of doors\n",
    "- `Weight`: Weight of the car in kilograms\n",
    "- `Price`: Price of the car in euros\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "The data is provided in the `data` folder and it contains the following 3 csv files:\n",
    "- `Task1-2.ToyotaCorolla.csv` for Part 1 and Part 2\n",
    "- `Task3.ToyotaCorolla_sales_3months.csv` for Part 3\n",
    "\n",
    "You should not use any other data source for this homework.\n",
    "\n",
    "For some questions, you might need to slightly modify the data. But overall, you should avoid making any major changes to the data, which may affect your analysis.\n",
    "\n",
    "## References:\n",
    "\n",
    "The data is based on the ToyotaCorolla dataset from the UCI Machine Learning Repository [here](https://archive.ics.uci.edu/ml/datasets/Toyota+Corolla).\n",
    "We have made some modifications to the original dataset, so please use the data provided in the `data` folder in the course repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36859d6",
   "metadata": {},
   "source": [
    "## Task 1 (20 pts) - Get to know the data"
   ]
  },
  {
   "cell_type": "code",
   "id": "ccd6fa08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T17:28:51.639042Z",
     "start_time": "2025-02-12T17:28:50.696292Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "import sklearn\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "f502c087",
   "metadata": {},
   "source": [
    "\n",
    "**1.1 (2 pts)**: Load the data from the file `Task1-2.ToyotaCorolla-raw.csv` into a pandas DataFrame. Display the first 5 rows of the DataFrame. Hint: A naive loading of the data will raise an error. You will need to figure out how to load the data correctly. (Hint: localise which row is causing the error)"
   ]
  },
  {
   "cell_type": "code",
   "id": "23cf0212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T17:28:51.648174Z",
     "start_time": "2025-02-12T17:28:51.644934Z"
    }
   },
   "source": [
    "#TODO\n",
    "# Define the correct path to your CSV file\n",
    "csv_path = \"data/Task1-2.ToyotaCorolla-raw.csv\"  # Ensure this matches the exact folder structure\n",
    "\n",
    "# Attempt to read the CSV file to identify errors\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    display(df.head())  # Display the first 5 rows\n",
    "except Exception as e:\n",
    "    print(\"Error loading dataset:\", e)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading dataset: Error tokenizing data. C error: Expected 11 fields in line 33, saw 12\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T17:28:51.691659Z",
     "start_time": "2025-02-12T17:28:51.681554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the path to your CSV file\n",
    "csv_path = \"data/Task1-2.ToyotaCorolla-raw.csv\"  # Update if needed\n",
    "\n",
    "# Read the file and filter only valid rows while storing problematic rows\n",
    "cleaned_rows = []\n",
    "problematic_rows = []\n",
    "\n",
    "with open(csv_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    header = f.readline().strip().split(\",\")  # Read header\n",
    "    num_columns = len(header)  # Count expected columns\n",
    "\n",
    "    for i, line in enumerate(f, start=2):  # Start at line 2 (after header)\n",
    "        row = line.strip().split(\",\")\n",
    "        if len(row) == num_columns:\n",
    "            cleaned_rows.append(row)  # Keep valid rows\n",
    "        else:\n",
    "            problematic_rows.append((i, len(row), line.strip()))  # Store problematic row number, column count, and content\n",
    "\n",
    "# Convert cleaned data to DataFrame\n",
    "df_cleaned = pd.DataFrame(cleaned_rows, columns=header)\n",
    "\n",
    "# Display the first few rows of the cleaned dataset\n",
    "display(df_cleaned.head())\n",
    "\n",
    "# Print expected column count\n",
    "print(f\"\\nExpected number of columns: {num_columns}\")\n",
    "\n",
    "# Print problematic rows with their actual column count\n",
    "print(\"\\nProblematic rows (row number, actual columns, content):\")\n",
    "for row in problematic_rows:\n",
    "    print(f\"Row {row[0]} (Columns: {row[1]}) -> {row[2]}\")\n"
   ],
   "id": "4b6770a0eb44bdb0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Price Age  Mileage FuelType  HP MetColor Automatic    CC Doors Weight  \\\n",
       "0  13500.0  23  46986.0   Diesel  90        1         0  2000     3   1165   \n",
       "1  11878.0  23  72937.0   Diesel  90        1         0  2000     3   1165   \n",
       "2  12050.0  24  41711.0   Diesel  90        1         0  2000     3   1165   \n",
       "3  12914.0  26  48000.0   Diesel  90        0         0  2000     3   1165   \n",
       "4  11878.0  30  38500.0   Diesel  90        0         0  2000     3   1170   \n",
       "\n",
       "  Currency  \n",
       "0     EURO  \n",
       "1      CHF  \n",
       "2      CHF  \n",
       "3      CHF  \n",
       "4      CHF  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>HP</th>\n",
       "      <th>MetColor</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>CC</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13500.0</td>\n",
       "      <td>23</td>\n",
       "      <td>46986.0</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>1165</td>\n",
       "      <td>EURO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11878.0</td>\n",
       "      <td>23</td>\n",
       "      <td>72937.0</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>1165</td>\n",
       "      <td>CHF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12050.0</td>\n",
       "      <td>24</td>\n",
       "      <td>41711.0</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>1165</td>\n",
       "      <td>CHF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12914.0</td>\n",
       "      <td>26</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>1165</td>\n",
       "      <td>CHF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11878.0</td>\n",
       "      <td>30</td>\n",
       "      <td>38500.0</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>1170</td>\n",
       "      <td>CHF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expected number of columns: 11\n",
      "\n",
      "Problematic rows (row number, actual columns, content):\n",
      "Row 33 (Columns: 12) -> 15,646.9,22,21862.732919254657,Petrol,97,1,0,1400,3,1100,GBP\n",
      "Row 36 (Columns: 13) -> \"15,398,499999999998\",22,25465.838509316767,Petrol,97,1,0,1400,3,1100,GBP\n",
      "Row 177 (Columns: 12) -> \"19,817.949999999997\",8,5325.465838509316,Petrol,110,1,0,1600,5,1130,GBP\n",
      "Row 225 (Columns: 12) -> \"14,851.099999999999\",44,44591.9254658385,CNG,110,1,0,1600,4,1067,GBP\n",
      "Row 344 (Columns: 12) -> \"14,851.099999999999\",42,18409.937888198758,Petrol,110,0,0,1600,3,1055,GBP\n",
      "Row 378 (Columns: 12) -> \"11,424.099999999999\",39,7453.416149068323,Petrol,110,1,0,1600,5,1075,GBP\n",
      "Row 413 (Columns: 12) -> \"10,877.849999999999\",52,61691.30434782608,Petrol,110,1,0,1600,3,1055,GBP\n",
      "Row 445 (Columns: 12) -> \"11,871.449999999999\",54,46727.32919254658,Petrol,110,1,0,1600,5,1080,GBP\n",
      "Row 469 (Columns: 12) -> \"11,871.449999999999\",56,41476.39751552795,Petrol,110,0,0,1600,5,1090,GBP\n",
      "Row 476 (Columns: 12) -> \"12,017.499999999998\",48,39871.42857142857,Petrol,110,1,0,1600,3,1040,GBP\n",
      "Row 479 (Columns: 12) -> \"9,864£\",53,39524.84472049689,Petrol,110,1,0,1600,4,1035,GBP\n",
      "Row 485 (Columns: 12) -> \"9,834£\",56,38975.776397515525,Petrol,110,0,0,1600,3,1050,GBP\n",
      "Row 531 (Columns: 12) -> \"13,659.699999999999\",54,30043.478260869564,Petrol,110,1,0,1600,5,1080,GBP\n",
      "Row 535 (Columns: 12) -> \"11,816.249999999998\",52,29620.496894409935,Petrol,110,0,0,1600,5,1075,GBP\n",
      "Row 653 (Columns: 12) -> \"7,898.2£\",68,71472.67080745341,Petrol,110,1,0,1600,3,1055,GBP\n",
      "Row 908 (Columns: 1) -> 8423.0;68;58860.0;Petrol;110;1;0;1600;3;1055;CHF\n",
      "Row 924 (Columns: 12) -> \"9,884.25\",63,35403.72670807453,Petrol,110,1,0,1600,3,1050,GBP\n",
      "Row 1019 (Columns: 12) -> \"8,842.349999999999\",68,21739.130434782608,Petrol,110,1,0,1600,3,1050,GBP\n",
      "Row 1052 (Columns: 12) -> \"8,449.999\",69,122671.42857142857,Diesel,72,0,0,2000,5,1135,GBP\n",
      "Row 1065 (Columns: 12) -> \"7,992.499999999999\",78,99359.00621118012,Diesel,72,0,0,2000,3,1115,GBP\n",
      "Row 1081 (Columns: 12) -> \"8,890.65\",79,86024.84472049688,Petrol,86,0,0,1300,5,1050,GBP\n",
      "Row 1103 (Columns: 12) -> \"6,406.65\",72,76647.82608695651,Petrol,110,1,0,1600,3,1050,GBP\n",
      "Row 1122 (Columns: 12) -> \"7,302.499999999999\",72,69565.21739130434,Petrol,86,1,0,1300,3,1015,GBP\n",
      "Row 1169 (Columns: 12) -> \"5,610.0\",74,96302.0,Petrol,86,1,0,1300,3,1015,CHF\n",
      "Row 1300 (Columns: 12) -> \"8,625.0\",78,44214.90683229813,Petrol,110,0,0,1600,3,1050,GBP\n",
      "Row 1330 (Columns: 12) -> \"6,855.15\",80,40563.354037267076,Petrol,110,1,0,1600,3,1055,GBP\n",
      "Row 1356 (Columns: 12) -> \"9,387.449999999999\",79,37355.27950310559,Petrol,110,0,0,1600,3,1050,GBP\n",
      "Row 1370 (Columns: 12) -> \"9,686.449999999999\",70,35918.63354037267,Petrol,110,0,0,1600,3,1050,GBP\n",
      "Row 1371 (Columns: 12) -> \"4,089.9999\",76,35987,Petrol,110,0,0,1600,3,1075,GBP\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* Some lines have more fields than it's defined based on columns. I will essentially just skip those then (when I opened in Excel, it seems to be the case that there are more problematics records besides the one in line 33).",
   "id": "937414316e05f96b"
  },
  {
   "cell_type": "markdown",
   "id": "b0b5f57b",
   "metadata": {},
   "source": [
    "**1.2 (2 pts)**: Check if there are nan values in the Dataframe. If there are, try to find out which row is problematic and fix it. If you can't fix it, drop the row."
   ]
  },
  {
   "cell_type": "code",
   "id": "a1197b0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T17:28:52.955197Z",
     "start_time": "2025-02-12T17:28:52.952213Z"
    }
   },
   "source": [
    "# Check if there are any NaN values in the DataFrame\n",
    "has_nan = df_cleaned.isna().any().any()\n",
    "\n",
    "# Print the result\n",
    "if has_nan:\n",
    "    print(\"There are NaN values in the DataFrame.\")\n",
    "else:\n",
    "    print(\"No NaN values found in the DataFrame.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values found in the DataFrame.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "303e0f76",
   "metadata": {},
   "source": [
    "**1.3 (4 pts): Compute the mean, median of the `Price` column.**\n",
    "\n",
    "- Compute the mean and median of the `Price` column. If you encounter error, try to understand why this error is happening and propose a solution.\n",
    "\n",
    "Hint: Is all values in the `Price` column numerical?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d7b18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a727c9",
   "metadata": {},
   "source": [
    "**1.4 (4 pts): Convert Units**\n",
    "\n",
    "You notice that some prices are in CHF (Swiss Francs), while others are in EUR (Euros) or GBP (British Pounds). Additionally, for cars priced in GBP, the mileage is in miles rather than kilometers.\n",
    "\n",
    "For consistency, convert all prices to EUR and all distances to kilometers.\n",
    "\n",
    "- Exchange rates:\n",
    "  - 1 CHF = 1.05 EUR\n",
    "  - 1 GBP = 1.15 EUR\n",
    "  - 1 mile = 1.61 km\n",
    "\n",
    "Make the following conversions:\n",
    "1. Convert prices in CHF or GBP to EUR, rounding to the nearest integer.\n",
    "2. Convert distances in miles (for GBP cars) to kilometers, rounding to the nearest integer.\n",
    "3. Drop the 'Currency' column.\n",
    "4. Calculate the min, mean, median and max of the 'Price' and 'Distance' columns after the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4fc4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf32bd",
   "metadata": {},
   "source": [
    "**1.5 (2 pts): Analyze Average Price**\n",
    "\n",
    "A.  Print the average price for each fuel type. Determine which fuel type has the highest average price.\n",
    "\n",
    "B.  Print the average price for different numbers of doors. Determine which number of doors has the highest average price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e405cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fa4698",
   "metadata": {},
   "source": [
    "**1.6 (2 pts): Relationship Between Car Age and Price**\n",
    "\n",
    "It is intuitive that an older car tends to be cheaper, and a car with more mileage might also be less expensive. \n",
    "\n",
    "To explore this intuition, create two scatter plots:\n",
    "1. Car Age vs Price\n",
    "2. Mileage vs Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ac6aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6531d1",
   "metadata": {},
   "source": [
    "**1.7 (4 pts): Correlation Between Price and Mileage**\n",
    "\n",
    "The relationship between car price and mileage appears non-linear, with a steeper price drop initially followed by a flatter curve.\n",
    "\n",
    "A.(2 pts)  Calculate both the Pearson and Spearman correlations between the price of the car and the distance driven.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "718ca9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3638a1",
   "metadata": {},
   "source": [
    "\n",
    "B.(2 pts)  Which correlation value is higher? Does this result align with your expectations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addf1654",
   "metadata": {},
   "source": [
    "Your Response:\n",
    "\n",
    "//**//"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4827d3d8",
   "metadata": {},
   "source": [
    "## Part 2 Linear Regression (30 pts)\n",
    "\n",
    "You want to build a linear regression model to predict the price of a car based on the features you have.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058120ef",
   "metadata": {},
   "source": [
    "**2.0 (8 pts) Helper functions**\n",
    "\n",
    "Before building the linear regression model, you need to implement some helper functions.\n",
    "\n",
    " Implement the `accuracy` , `precision`, `recall` and `f1_score` functions. \n",
    "\n",
    "1. These functions should take in the true labels(`np.array`) and the predicted labels(`np.array`) and return the corresponding metric. \n",
    "2. They should follow the convention that the positive class is 1 and the negative class is 0.\n",
    "3. Apply the functions to the following data:\n",
    "\n",
    "```python\n",
    "true_labels = np.array([1, 0, 1, 1, 0, 1, 0, 0, 1, 0])\n",
    "predicted_labels = np.array([1, 1, 1, 1, 0, 0, 1, 0, 1, 0])\n",
    "```\n",
    "\n",
    "- Compare the results with the implementation in `sklearn` and see if they match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e5cff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e49af9",
   "metadata": {},
   "source": [
    "\n",
    "**2.1 (6 pts) Preprocess the Data**\n",
    "\n",
    "To prepare your data for building a linear regression model, complete the following steps:\n",
    "\n",
    "A.(1 pts) Convert the categorical variables to one-hot encoding using the `pd.get_dummies()` function, how many columns do you have after the one-hot encoding? (P.S. You may want to avoid introducing multicollinearity with one-hot encoding, what should you do to avoid this?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f65013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f24e26",
   "metadata": {},
   "source": [
    "B.(1 pts) Split the data into features (X) and target (y) variables. The target variable is the 'Price' column. Then split the data into train test sets using a 80-20 split. Use `random_state=42` for reproducibility. How many samples are in the training set and how many samples are in the test set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f3ea52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6992805",
   "metadata": {},
   "source": [
    "C.(1 pts) Why do we split the data into only train-test sets but not train-validation-test sets? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038285f4",
   "metadata": {},
   "source": [
    "Your Response:\n",
    "\n",
    "//**//"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1b8bdf",
   "metadata": {},
   "source": [
    "D.(1 pts) **Standardize the Features**: Use `StandardScaler` from `sklearn.preprocessing` and then add a constant column using `sm.add_constant()`. Print the average and standard deviation of the training set after standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0743e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebec9402",
   "metadata": {},
   "source": [
    "E.(2 pts) Should we first standardize the data and then split it into train and test sets or vice versa?   why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dfe2b6",
   "metadata": {},
   "source": [
    "Your Response:\n",
    "\n",
    "//**//"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012c220d",
   "metadata": {},
   "source": [
    "**2.2 (10 pts) Train and Evaluate the Linear Regression Model**\n",
    "\n",
    "To train a linear regression model using and evaluate its performance, follow these steps:\n",
    "\n",
    "1. (2 pts) Train a linear regression model on the training dataset using `sm.OLS` from `statsmodels`, print the summary of the model using `model.summary()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4b338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4bdce",
   "metadata": {},
   "source": [
    "2. (2 pts) Evaluate the model on the test dataset using the square root of the mean squared error (RMSE) metric. \n",
    "   1. Report the RMSE value.\n",
    "   2. Your boss wants to know how far off the model's predictions are from the actual price of the car. What would you tell him? Given a number and explain how you got it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7936208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92955c02",
   "metadata": {},
   "source": [
    "Your Response:\n",
    "\n",
    "//**//"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a1de71",
   "metadata": {},
   "source": [
    "3. (2 pts) Report the R² score on the test dataset and interpret it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1a4355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe57aee",
   "metadata": {},
   "source": [
    "Your Response:\n",
    "\n",
    "//**//"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9191203",
   "metadata": {},
   "source": [
    "4.  (2 pts) Which features are statistically significant at a 5% significance level? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "782d34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff41e0",
   "metadata": {},
   "source": [
    "5.  (2 pts) Determine which two feature have the highest coefficient? What does it imply?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd51a86",
   "metadata": {},
   "source": [
    "Your Response:\n",
    "\n",
    "//**//"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af624b8",
   "metadata": {},
   "source": [
    "**2.3 (2 pts): Improvement Discussion**\n",
    "\n",
    "- Suggest a few additional features that could potentially explain this remaining variance in the data ( at least 2 features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d36c87",
   "metadata": {},
   "source": [
    "Your Response:\n",
    "\n",
    "//**//"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ca03f3",
   "metadata": {},
   "source": [
    "**2.4 (2 pts): Identifying Confounding Variables**\n",
    "\n",
    "The feature \"Weight\" shows a very low p-value and a high coefficient, but it doesn't seem to be a major factor for customers buying a second-hand car. You go to your mentor Jerasimosu to discuss this issue. Indeed, Jerasimosu suggests that never in his career has he seen a customer who asked for the weight of a car before buying it.\n",
    "You suspect that there might be a confounding variable that is correlated with the car's weight and significantly influences its price.\n",
    "\n",
    "- Suggest a possible confounding variable that may be correlated with the car's weight and significantly influence its price (it doesn't need to be a variable in the dataset). Explain why this variable could be a confounding variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677c957",
   "metadata": {},
   "source": [
    "Your Response:\n",
    "\n",
    "//**//"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2854b8",
   "metadata": {},
   "source": [
    "**2.5 (2 pts): Adding an Inverse Mileage Term**\n",
    "\n",
    "From the previous scatter plot, the relationship between car price and mileage appears non-linear, with a steep price drop initially and then a flattening. A suitable approach to model this behavior is by incorporating an inverse term of mileage.\n",
    "\n",
    "- Add the inverse mileage term to the model and retrain it using the code provided. Print the model summary and interpret the effect of the inverse mileage term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a4b261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3c61dc",
   "metadata": {},
   "source": [
    "## Part 3 Supervised Learning (40 pts)\n",
    "\n",
    "\n",
    "After completing your analysis, you're satisfied with the results. You handed the Jupyter notebook over to your mentor.\n",
    "\n",
    "(Fun fact: The name \"Jupyter\" is derived from Julia, Python, and R—three programming languages that the platform was originally designed for.)\n",
    "\n",
    "Your mentor Jerasimosu is very impressed with your work and asks you the following question:\n",
    "\n",
    "“\n",
    "This looks great! It will be very useful for our sales team. While looking at the results, I realized that there might be one thing that we can improve. \n",
    "For companies like us, it is important to sell the cars quickly. If we are patient, we might be able to sell the car for a higher price, but that’s not always the best strategy. We need to consider the maintenance costs for the car, the cash flow and the fact that the price of the car decreases over time.\"\n",
    "\n",
    "He then continues:\n",
    "\"Three months is a sweet spot for us. If we can sell the car within the first three months, it is great. If not, it is worth considering lowering the price to sell it faster and increase our cash flow. I can ask Ivan from Sales to collect data in the last few months on whether the car was sold within the first three months or not. This would be great if you could have a model that tells us if the car will be sold in the first three months or not. \"\n",
    "\n",
    "This sparks your interest, and soon Ivan has provided you with the new data containing an additional column `sold_within_3_months` which is a binary variable indicating whether the car was sold within the first three months or not.\n",
    "\n",
    "Note: The data for this part is in the file `Task3.ToyotaCorolla_sales_3months.csv` and it has already unified the currency and distance units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5371de93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m data_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/Task3.ToyotaCorolla_sales_3months.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(data_df\u001B[38;5;241m.\u001B[39mhead())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv('data/Task3.ToyotaCorolla_sales_3months.csv', index_col=0)\n",
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af3424",
   "metadata": {},
   "source": [
    "\n",
    "**3.1 (2 pts): Preprocess the Data**\n",
    "- （1 pts）How many cars in the dataset were sold in the first three months, and how many were not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "714cefb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49dc91",
   "metadata": {},
   "source": [
    "- (1 pts) Preprocess the categorical variables to one-hot encoding using the `pd.get_dummies()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9ca7824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1449cf1c",
   "metadata": {},
   "source": [
    "**3.2 (20 pts):  Logistic Regression Model**\n",
    "1. (2 pts) Split the data into features (X) and target (y) variables. The target variable is the 'sold_within_3_months' column. The `Price` column should be included as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bda17a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28393827",
   "metadata": {},
   "source": [
    "2. (2 pts) Then split the data into train test sets using a 80-20 split. Use `random_state=42` for reproducibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7416161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f0fbf",
   "metadata": {},
   "source": [
    "3. (2 pts) Standardize the features using `StandardScaler` from `sklearn.preprocessing` and then add a constant column using `sm.add_constant()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16bfc69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7029f6",
   "metadata": {},
   "source": [
    "4. (2 pts) Fit a logistic regression model on the training dataset. Feel free to use either `statsmodels` or `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d7e52e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c3b275",
   "metadata": {},
   "source": [
    "5. (2 pts) Evaluate the model on the test dataset using the accuracy score metric. Report the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2152d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b5d10b",
   "metadata": {},
   "source": [
    "6. (2 pts) Calculate the precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93ef377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83bb422",
   "metadata": {},
   "source": [
    "7. (2 pts) Suppose that your company is running short on cash flow and needs to sell the cars quickly, for example by running some offer (special discount on cars). But which ones? How should you adjust the threshold for the decision boundary of the logistic regression model to ensure that the company can sell the cars as quickly as possible?\n",
    "    - A. Increase the threshold\n",
    "    - B. Decrease the threshold\n",
    "\n",
    "In a more general sense, how does the choice of threshold affect the precision and recall of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1951dc8",
   "metadata": {},
   "source": [
    "Your Response:\n",
    "\n",
    "//**//"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a1414",
   "metadata": {},
   "source": [
    "8. (6 pts) Try to find the optimal threshold that maximizes the F1-score. Implement any kind of method you see fit (e.g. binary search or grid search). What is the optimal threshold and what difference does the optimal threshold make in the F1-score?\n",
    "\n",
    "If you notice anything odd, report it and try to identify the reasons behind it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecc90348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53796e48",
   "metadata": {},
   "source": [
    "**3.3(23 pts) Free model exploration**\n",
    "\n",
    "Use any model from `sklearn` to predict whether a car will be sold within the first three months.\n",
    "\n",
    "Follow these steps to complete the task:\n",
    "\n",
    "1. (2 pts) Train your own classifier model to predict the target variable (`sold_within_3_months`).You can reuse the train and test sets from the previous section. Set `random_state=42` for reproducibility if needed. At this stage no need to optimize (yet). That will come at step 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "847d2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e84a7",
   "metadata": {},
   "source": [
    "2. (2 pts) Evaluate the model on the test set and report on hyperparameters or other details of the algorithm you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f91de524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeacddbc",
   "metadata": {},
   "source": [
    "3. (2 pts) Come up with a visualization (could be related to the model or to some variables (e.g. EDA plots) to demonstrate the difficulty (or not) of the problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3899ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f27b0",
   "metadata": {},
   "source": [
    "4. (17 pts) Try to come up with a model that improves the results both in the previous seciton but also your baseline model in 3.1. Make to sure to properly evaluate the model. No need to provide a visualization here but feel free to add any supporting evidence to your modeling.\n",
    "\n",
    "Minimally (and for a high-grade) you should consider some form of regularization and proper cross-validation. \n",
    "\n",
    "Other things you can consider (in no particular order) are feature engineering, model robustness, hyperparameter tuning, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c23ea3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89384315",
   "metadata": {},
   "source": [
    "## Part 4 The Aftermath (5 pts)\n",
    "\n",
    "Machine learning models are often evaluated based on accuracy, precision and recall, but these metrics do not always capture fairness. Fairness is a broader concept that depends on the context of the dataset and the decisions influenced by the model.\n",
    "\n",
    "For this last question, you are asked to reflect on what fairness means in the context of this problem. More specifically, identify potential fairness concerns (at least 2) and suggest how they could be measured or mitigated.\n",
    "Explain why fairness matters (or doesn’t) in this specific context.\n",
    "\n",
    "*Hint: Think of the whole pipeline of data science: data collection, modeling, evaluation and identify sources of where the model might be unfair.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd5ceda",
   "metadata": {},
   "source": [
    "Your Response:\n",
    "\n",
    "//**//"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
